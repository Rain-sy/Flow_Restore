import argparse
import yaml
import torch
import os
import numpy as np
from PIL import Image
from diffusers import StableDiffusion3Pipeline
# ç¡®ä¿ä½ çš„ FlowEdit_utils å·²ç»ä¿®æ”¹è¿‡ï¼Œæ”¯æŒ coupling_strength
from FlowEdit_utils import FlowEditSD3

def load_yaml(path):
    """å®‰å…¨åŠ è½½åŒ…å«ä¸­æ–‡è·¯å¾„çš„ YAML"""
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.load(f, Loader=yaml.FullLoader)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--device_number", type=int, default=0, help="GPU device ID")
    parser.add_argument("--exp_yaml", type=str, default="SD3_denoise.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()
    
    device_id = args.device_number
    device = torch.device(f"cuda:{device_id}" if torch.cuda.is_available() else "cpu")
    
    pipe = StableDiffusion3Pipeline.from_pretrained(
        "stabilityai/stable-diffusion-3-medium-diffusers", 
        torch_dtype=torch.float16
    )
    
    pipe = pipe.to(device)
    
    # è·å– Scheduler
    scheduler = pipe.scheduler

    # 3. è¯»å–å®éªŒé…ç½®
    exp_configs = load_yaml(args.exp_yaml)

    # 4. å¼€å§‹å¾ªç¯å®éªŒ
    for exp_dict in exp_configs:
        exp_name = exp_dict.get("exp_name", "SD3_Restoration")
        dataset_yaml = exp_dict["dataset_yaml"]
        
        # è¯»å–å‚æ•° (æä¾›é»˜è®¤å€¼ä»¥é˜² YAML æ¼å†™)
        T_steps = exp_dict.get("T_steps", 50)
        n_avg = exp_dict.get("n_avg", 1)
        n_min = exp_dict.get("n_min", 15)
        n_max = exp_dict.get("n_max", 45)
        
        # å…³é”®å‚æ•°
        src_guidance_scale = exp_dict.get("src_guidance_scale", 4.5)
        tar_guidance_scale = exp_dict.get("tar_guidance_scale", 8.5)
        coupling_strength = exp_dict.get("coupling_strength", 0.6) # é»˜è®¤ 0.6
        
        seed = exp_dict.get("seed", 42)

        print(f"\nğŸ¨ Starting Experiment: {exp_name}")
        print(f"   Steps: {T_steps} | Coupling: {coupling_strength} | n_min: {n_min}")
        print(f"   Guidance: Src={src_guidance_scale} / Tar={tar_guidance_scale}")

        # è®¾ç½®éšæœºç§å­
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        np.random.seed(seed)

        # åŠ è½½æ•°æ®é…ç½®
        dataset_configs = load_yaml(dataset_yaml)

        for data_dict in dataset_configs:
            image_path = data_dict["input_img"]
            src_prompt = data_dict["source_prompt"]
            tar_prompts = data_dict["target_prompts"]
            
            # è·å– target_codes (ç”¨äºå‘½å)ï¼Œå¦‚æœæ²¡æœ‰å°±ç”¨ç´¢å¼•
            target_codes = data_dict.get("target_codes", [])

            # --- å›¾åƒé¢„å¤„ç† ---
            if not os.path.exists(image_path):
                print(f"âŒ Error: Image not found: {image_path}")
                continue
            
            # å¼ºåˆ¶è½¬ RGB (ä¿®å¤ 4 é€šé“æŠ¥é”™)
            image_raw = Image.open(image_path)
            
            # è°ƒæ•´å°ºå¯¸ä¸º 16 çš„å€æ•° (é¿å… VAE æŠ¥é”™)
            w, h = image_raw.size
            new_w = w - (w % 16)
            new_h = h - (h % 16)
            if new_w != w or new_h != h:
                image_raw = image_raw.resize((new_w, new_h), Image.LANCZOS)

            # é¢„å¤„ç†å¹¶ç¼–ç è¿› VAE
            image_tensor = pipe.image_processor.preprocess(image_raw).to(device).half()
            
            with torch.no_grad():
                # ç¼–ç  Latents
                x0_src_denorm = pipe.vae.encode(image_tensor).latent_dist.mode()
                # å½’ä¸€åŒ– Latents
                x0_src = (x0_src_denorm - pipe.vae.config.shift_factor) * pipe.vae.config.scaling_factor

            # --- å¼€å§‹ç¼–è¾‘ ---
            for i, tar_prompt in enumerate(tar_prompts):
                
                # ç¡®å®šè¾“å‡ºæ ‡è¯†
                code_suffix = target_codes[i] if i < len(target_codes) else str(i)
                
                print(f"   Processing: {os.path.basename(image_path)} -> {code_suffix}")

                # è°ƒç”¨æ ¸å¿ƒç®—æ³• (ç¡®ä¿ utils é‡Œæœ‰ coupling_strength å‚æ•°)
                x0_tar = FlowEditSD3(
                    pipe,
                    scheduler,
                    x0_src,
                    src_prompt,
                    tar_prompt,
                    negative_prompt="", # SD3 é€šå¸¸ä¸éœ€è¦æ˜¾å¼è´Ÿé¢æç¤ºè¯ï¼Œé™¤é guidance > 1
                    T_steps=T_steps,
                    n_avg=n_avg,
                    src_guidance_scale=src_guidance_scale,
                    tar_guidance_scale=tar_guidance_scale,
                    n_min=n_min,
                    n_max=n_max,
                    coupling_strength=coupling_strength # <--- ä¼ å…¥è¿™ä¸ªå…³é”®å‚æ•°
                )

                # è§£ç  Latents -> Image
                x0_tar_denorm = (x0_tar / pipe.vae.config.scaling_factor) + pipe.vae.config.shift_factor
                with torch.no_grad():
                    image_out = pipe.vae.decode(x0_tar_denorm, return_dict=False)[0]
                
                image_out = pipe.image_processor.postprocess(image_out)[0]

                # --- æ™ºèƒ½ä¿å­˜é€»è¾‘ ---
                # 1. è§£æè·¯å¾„ç»“æ„ï¼Œæå–çˆ¶æ–‡ä»¶å¤¹å (é€‚é… SIDD ç­‰å¤æ‚æ•°æ®é›†)
                # å°†è·¯å¾„ç»Ÿä¸€ä¸ºæ­£æ–œæ å¤„ç†
                path_parts = image_path.replace("\\", "/").split("/")
                
                if len(path_parts) >= 2:
                    # ä¾‹å¦‚ Data/001/NOISY.png -> 001_NOISY
                    src_folder_name = f"{path_parts[-2]}_{path_parts[-1].split('.')[0]}"
                else:
                    src_folder_name = path_parts[-1].split('.')[0]

                # 2. æ„å»ºä¿å­˜ç›®å½•
                # output/å®éªŒå/SD3/åŸå›¾ID/ç›®æ ‡ID
                save_dir = f"outputs/{exp_name}/SD3/{src_folder_name}/{code_suffix}"
                os.makedirs(save_dir, exist_ok=True)

                # 3. æ„å»ºè¯¦ç»†æ–‡ä»¶å (å¸¦å‚æ•°)
                filename = (f"cp{coupling_strength}_nmin{n_min}_"
                            f"src{src_guidance_scale}_tar{tar_guidance_scale}.png")
                
                save_path = os.path.join(save_dir, filename)
                image_out.save(save_path)
                print(f"      âœ… Saved: {save_path}")

    print("\nğŸ‰ All Done!")