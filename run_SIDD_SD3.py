import torch
from diffusers import StableDiffusion3Pipeline
from PIL import Image
import argparse
import random 
import numpy as np
import yaml
import os
# åªéœ€è¦å¯¼å…¥ SD3 çš„å·¥å…·
from FlowEdit_utils import FlowEditSD3

if __name__ == "__main__":

    parser = argparse.ArgumentParser()
    parser.add_argument("--device_number", type=int, default=0, help="device number to use")
    parser.add_argument("--exp_yaml", type=str, default="sidd_denoise.yaml", help="experiment yaml file")

    args = parser.parse_args()

    # set device
    device_number = args.device_number
    # è¿™é‡Œå®šä¹‰ device å˜é‡ï¼Œä½†åé¢ä¸»è¦é  cpu_offload ç®¡ç†
    device = torch.device(f"cuda:{device_number}" if torch.cuda.is_available() else "cpu")

    # load exp yaml file to dict
    exp_yaml = args.exp_yaml
    with open(exp_yaml, encoding='utf-8') as file:
        exp_configs = yaml.load(file, Loader=yaml.FullLoader)

    print(f"ğŸš€ Initializing SD3 for SIDD Restoration...")

    # 1. åŠ è½½ SD3 æ¨¡å‹
    # æ—¢ç„¶åªç”¨ SD3ï¼Œç›´æ¥å†™æ­»åŠ è½½é€»è¾‘ï¼Œä¸å†åˆ¤æ–­ model_type
    pipe = StableDiffusion3Pipeline.from_pretrained(
        "stabilityai/stable-diffusion-3-medium-diffusers", 
        torch_dtype=torch.float16
    )
    
    scheduler = pipe.scheduler
    
    # 2. å¼€å¯ CPU Offload (8GB æ˜¾å­˜ä¼˜åŒ–)
    print("ğŸ’¡ Enabling Model CPU Offload...")
    pipe.enable_model_cpu_offload()

    for exp_dict in exp_configs:

        exp_name = exp_dict["exp_name"]
        model_type = "SD3" # å›ºå®šä¸º SD3
        
        T_steps = exp_dict["T_steps"]
        n_avg = exp_dict["n_avg"]
        src_guidance_scale = exp_dict["src_guidance_scale"]
        tar_guidance_scale = exp_dict["tar_guidance_scale"]
        n_min = exp_dict["n_min"]
        n_max = exp_dict["n_max"]
        seed = exp_dict["seed"]

        # set seed
        random.seed(seed)
        np.random.seed(seed)
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        
        dataset_yaml = exp_dict["dataset_yaml"]
        with open(dataset_yaml, encoding='utf-8') as file:
            dataset_configs = yaml.load(file, Loader=yaml.FullLoader)

        # éå†æ•°æ®é›†å›¾ç‰‡
        for data_dict in dataset_configs:

            src_prompt = data_dict["source_prompt"]
            tar_prompts = data_dict["target_prompts"]
            
            # è·å– target_codes (å¦‚æœ YAML é‡Œæœ‰å°±ç”¨ï¼Œæ²¡æœ‰å°±ç”¨ç´¢å¼•)
            target_codes = data_dict.get("target_codes", [])
            
            negative_prompt = "" 
            image_src_path = data_dict["input_img"]

            # check image existence
            if not os.path.exists(image_src_path):
                print(f"âŒ Error: Image not found: {image_src_path}")
                continue

            # load image
            # å¼ºåˆ¶è½¬ RGBï¼Œé˜²æ­¢ PNG çš„ Alpha é€šé“å¯¼è‡´æŠ¥é”™
            image = Image.open(image_src_path).convert("RGB")
            
            # crop image to have both dimensions divisibe by 16
            # ä½¿ç”¨ LANCZOS ç¼©æ”¾é€šå¸¸æ¯”ç›´æ¥ crop æ›´å¥½ï¼Œä½†ä¿ç•™ä½ çš„ crop é€»è¾‘ä¹Ÿè¡Œ
            # è¿™é‡Œç¨å¾®ä¼˜åŒ–äº†ä¸€ä¸‹é€»è¾‘ï¼Œç¡®ä¿ crop ä¸ä¼šå‡ºé”™
            w, h = image.size
            new_w = w - (w % 16)
            new_h = h - (h % 16)
            if new_w != w or new_h != h:
                image = image.crop((0, 0, new_w, new_h))
            
            image_src = pipe.image_processor.preprocess(image)
            
            # cast image to half precision
            image_src = image_src.to(device).half()
            
            # VAE Encode
            with torch.autocast("cuda"), torch.inference_mode():
                x0_src_denorm = pipe.vae.encode(image_src).latent_dist.mode()
            
            x0_src = (x0_src_denorm - pipe.vae.config.shift_factor) * pipe.vae.config.scaling_factor
            x0_src = x0_src.to(device)
            
            # ================= SIDD è·¯å¾„å¤„ç†æ ¸å¿ƒé€»è¾‘ =================
            # SIDD çš„å›¾ç‰‡åéƒ½æ˜¯ NOISY_SRGB_010.PNGï¼Œå¦‚æœä¸å¤„ç†ä¼šè¦†ç›–
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šå¦‚æœè·¯å¾„åŒ…å«çˆ¶æ–‡ä»¶å¤¹ï¼Œå°±æŠŠçˆ¶æ–‡ä»¶å¤¹åæ‹¼ä¸Šå»
            path_parts = image_src_path.replace("\\", "/").split("/")
            
            if len(path_parts) >= 2:
                # ä¾‹å¦‚: 001_NOISY_SRGB_010
                src_prompt_txt = f"{path_parts[-2]}_{path_parts[-1].split('.')[0]}"
            else:
                src_prompt_txt = path_parts[-1].split('.')[0]
            # =======================================================
            
            for tar_num, tar_prompt in enumerate(tar_prompts):

                # ç¡®å®šç›®æ ‡æ–‡ä»¶å¤¹åç§°
                if tar_num < len(target_codes):
                    tar_prompt_txt = target_codes[tar_num]
                else:
                    tar_prompt_txt = str(tar_num)

                print(f"Processing: {src_prompt_txt} -> {tar_prompt_txt}")

                # è°ƒç”¨ FlowEditSD3 (å·²ç§»é™¤ coupling_strength)
                x0_tar = FlowEditSD3(
                    pipe,
                    scheduler,
                    x0_src,
                    src_prompt,
                    tar_prompt,
                    negative_prompt,
                    T_steps=T_steps,
                    n_avg=n_avg,
                    src_guidance_scale=src_guidance_scale,
                    tar_guidance_scale=tar_guidance_scale,
                    n_min=n_min,
                    n_max=n_max
                    # æ³¨æ„ï¼šè¿™é‡Œä¸å†ä¼ é€’ coupling_strength
                )

                # Decode
                x0_tar_denorm = (x0_tar / pipe.vae.config.scaling_factor) + pipe.vae.config.shift_factor
                with torch.autocast("cuda"), torch.inference_mode():
                    image_tar = pipe.vae.decode(x0_tar_denorm, return_dict=False)[0]
                
                image_tar = pipe.image_processor.postprocess(image_tar)
                
                # æ„é€ ä¿å­˜è·¯å¾„
                # ç»“æ„: outputs/å®éªŒå/SD3/src_åœºæ™¯ID/tar_code/æ–‡ä»¶å.png
                save_dir = f"outputs/{exp_name}/{model_type}/src_{src_prompt_txt}/tar_{tar_prompt_txt}"
                os.makedirs(save_dir, exist_ok=True)
                
                output_filename = f"n_min_{n_min}_n_max_{n_max}_src{src_guidance_scale}_tar{tar_guidance_scale}_T_steps_{T_steps}.png"
                save_path = f"{save_dir}/{output_filename}"
                
                image_tar[0].save(save_path)
                print(f"   Saved to: {save_path}")

    print("Done")