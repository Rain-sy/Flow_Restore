import torch
from diffusers import StableDiffusion3Pipeline
from PIL import Image
import argparse
import random 
import numpy as np
import yaml
import os
import math
from tqdm import tqdm
# å¯¼å…¥ SD3 å·¥å…·
from FlowEdit_utils import FlowEditSD3

def load_yaml(path):
    with open(path, 'r', encoding='utf-8') as f:
        return yaml.load(f, Loader=yaml.FullLoader)

def process_tile_sd3(pipe, scheduler, image_tile, prompt_config, run_args, device):
    """
    å¤„ç†å•ä¸ª 1024x1024 çš„å°å— (SD3 ç‰ˆæœ¬)
    """
    # 1. é¢„å¤„ç†
    # SD3 éœ€è¦å®½å’Œé«˜æ˜¯ 16 çš„å€æ•° (è™½ç„¶ 1024 è‚¯å®šæ˜¯ï¼Œä½†åŠ ä¸ªä¿é™©)
    w, h = image_tile.size
    w = w - (w % 16)
    h = h - (h % 16)
    if w != image_tile.size[0] or h != image_tile.size[1]:
        image_tile = image_tile.crop((0, 0, w, h))

    image_src = pipe.image_processor.preprocess(image_tile)
    image_src = image_src.to(device).half()
    
    # 2. VAE ç¼–ç 
    with torch.autocast("cuda"), torch.inference_mode():
        x0_src_denorm = pipe.vae.encode(image_src).latent_dist.mode()
    
    x0_src = (x0_src_denorm - pipe.vae.config.shift_factor) * pipe.vae.config.scaling_factor

    # 3. FlowEdit SD3 ä¿®å¤
    # æ³¨æ„ï¼šè¿™é‡Œä¸å†ä¼ é€’ coupling_strength
    x0_tar = FlowEditSD3(
        pipe,
        scheduler,
        x0_src,
        src_prompt=prompt_config["source"],
        tar_prompt=prompt_config["target"],
        negative_prompt="", # SD3 é»˜è®¤ç©ºè´Ÿé¢æç¤ºè¯
        T_steps=run_args["steps"],
        n_avg=1,
        src_guidance_scale=run_args["src_cfg"],
        tar_guidance_scale=run_args["tar_cfg"],
        n_min=run_args["n_min"],
        n_max=run_args["n_max"]
    )

    # 4. VAE è§£ç 
    x0_tar_denorm = (x0_tar / pipe.vae.config.scaling_factor) + pipe.vae.config.shift_factor
    with torch.autocast("cuda"), torch.inference_mode():
        image_tar = pipe.vae.decode(x0_tar_denorm, return_dict=False)[0]
    
    # è½¬å› Tensor (C, H, W) èŒƒå›´ [0, 1]ï¼Œæ–¹ä¾¿æ‹¼å›¾
    # image_tar æ˜¯ [-1, 1]ï¼Œéœ€è¦ denormalize
    image_tar = (image_tar / 2 + 0.5).clamp(0, 1).cpu().squeeze(0)
    return image_tar

def tiled_inference_sd3(pipe, scheduler, image_path, prompt_config, args, device):
    """
    æ ¸å¿ƒåˆ†å—é€»è¾‘ï¼šæ»‘çª—å¤„ç† + åŠ æƒèåˆ
    """
    full_image = Image.open(image_path).convert("RGB")
    W, H = full_image.size
    
    # === åˆ†å—é…ç½® ===
    # SD3 æœ€ä½³åˆ†è¾¨ç‡æ˜¯ 1024
    TILE_SIZE = 1024    
    # æ­¥é•¿ 768ï¼Œæ„å‘³ç€æœ‰ 256px çš„é‡å åŒºåŸŸç”¨äºå¹³æ»‘æ¥ç¼
    STRIDE = 768        
    
    # åˆ›å»ºå¤§ç”»å¸ƒ (ç´¯åŠ å™¨)
    full_canvas = torch.zeros((3, H, W), dtype=torch.float32)
    count_canvas = torch.zeros((3, H, W), dtype=torch.float32)

    print(f"   ğŸ§© Tiling: {W}x{H} -> Grid with {TILE_SIZE}x{TILE_SIZE} tiles...")

    # ç”Ÿæˆæ»‘çª—åæ ‡
    h_starts = list(range(0, H - TILE_SIZE + 1, STRIDE))
    if (H - TILE_SIZE) % STRIDE != 0: h_starts.append(H - TILE_SIZE)
    
    w_starts = list(range(0, W - TILE_SIZE + 1, STRIDE))
    if (W - TILE_SIZE) % STRIDE != 0: w_starts.append(W - TILE_SIZE)
    
    h_starts = sorted(list(set(h_starts)))
    w_starts = sorted(list(set(w_starts)))

    total_tiles = len(h_starts) * len(w_starts)
    pbar = tqdm(total=total_tiles, desc="Processing Tiles", leave=False)

    for y in h_starts:
        for x in w_starts:
            # 1. åˆ‡ç‰‡
            box = (x, y, x + TILE_SIZE, y + TILE_SIZE)
            tile_pil = full_image.crop(box)
            
            # 2. å¤„ç† (FlowEdit SD3)
            tile_tensor = process_tile_sd3(
                pipe, scheduler, tile_pil, 
                prompt_config, 
                args, 
                device
            )
            
            # 3. æ‹¼å›å»
            full_canvas[:, y:y+TILE_SIZE, x:x+TILE_SIZE] += tile_tensor
            count_canvas[:, y:y+TILE_SIZE, x:x+TILE_SIZE] += 1.0
            
            pbar.update(1)
    
    pbar.close()

    # 4. å–å¹³å‡
    result_tensor = full_canvas / count_canvas
    
    # è½¬å› PIL
    result_img = result_tensor.permute(1, 2, 0).numpy() # (H, W, 3)
    result_img = (result_img * 255).astype(np.uint8)
    return Image.fromarray(result_img)

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--device_number", type=int, default=0, help="GPU ID")
    parser.add_argument("--exp_yaml", type=str, default="sidd_denoise.yaml")
    args_cli = parser.parse_args()
    
    device = torch.device(f"cuda:{args_cli.device_number}" if torch.cuda.is_available() else "cpu")
    exp_configs = load_yaml(args_cli.exp_yaml)

    print(f"ğŸš€ Initializing SD3 Tiled Restoration (Server Mode)...")

    # åŠ è½½ SD3
    pipe = StableDiffusion3Pipeline.from_pretrained(
        "stabilityai/stable-diffusion-3-medium-diffusers", 
        torch_dtype=torch.float16
    )
    
    # æœåŠ¡å™¨æ¨¡å¼ï¼šç›´æ¥ä¸Š GPU
    try:
        pipe.to(device)
        print("âš¡ Model loaded directly to GPU")
    except:
        print("âš ï¸ Falling back to CPU Offload")
        pipe.enable_model_cpu_offload()
    
    scheduler = pipe.scheduler

    for exp_dict in exp_configs:
        exp_name = exp_dict.get("exp_name", "SD3_Tiled")
        
        # æå–å‚æ•°
        run_args = {
            "steps": exp_dict.get("T_steps", 50),
            "n_min": exp_dict.get("n_min", 20),
            "n_max": exp_dict.get("n_max", 45),
            "src_cfg": exp_dict.get("src_guidance_scale", 4.5),
            "tar_cfg": exp_dict.get("tar_guidance_scale", 9.0)
        }
        
        seed = exp_dict.get("seed", 42)
        random.seed(seed); np.random.seed(seed); torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)

        dataset_configs = load_yaml(exp_dict["dataset_yaml"])

        for data_dict in dataset_configs:
            image_src_path = data_dict["input_img"]
            
            # ================= å…³é”®ä¿®æ”¹ï¼šç­›é€‰é€»è¾‘ =================
            # è¿™é‡Œçš„é€»è¾‘æ˜¯ï¼šæ£€æŸ¥è·¯å¾„å­—ç¬¦ä¸²ä¸­æ˜¯å¦åŒ…å« "_N" 
            # (SIDD å‘½åä¹ æƒ¯: ..._3200_N, ..._4400_L)
            # å¦‚æœä¸åŒ…å«ï¼Œå°±è·³è¿‡
            if "_N" not in image_src_path and "_N/" not in image_src_path:
                # print(f"Skipping non-'N' image: {image_src_path}")
                continue
            # ====================================================

            if not os.path.exists(image_src_path): continue

            # å‡†å¤‡ Prompt
            prompt_config = {
                "source": data_dict["source_prompt"],
                "target": data_dict["target_prompts"][0]
            }
            
            # è·å– Scene ID
            path_parts = image_src_path.replace("\\", "/").split("/")
            if len(path_parts) >= 2:
                # ä¾‹å¦‚: 0002_001_S6_..._N
                scene_id = path_parts[-2]
            else:
                scene_id = path_parts[-1].split('.')[0]
            
            print(f"ğŸ–¼ï¸ Processing Tiled SD3: {scene_id} ...")
            
            # è°ƒç”¨ Tiling å‡½æ•°
            final_image = tiled_inference_sd3(
                pipe, scheduler, image_src_path, 
                prompt_config, run_args, device
            )
            
            # ä¿å­˜
            # ç»“æ„: outputs/å®éªŒå/SD3_Tiled/SceneID/å‚æ•°.png
            save_dir = f"outputs/{exp_name}/SD3_Tiled/{scene_id}"
            os.makedirs(save_dir, exist_ok=True)
            
            filename = f"nmin{run_args['n_min']}_src{run_args['src_cfg']}_tar{run_args['tar_cfg']}.png"
            save_path = f"{save_dir}/{filename}"
            
            final_image.save(save_path)
            print(f"âœ… Saved: {save_path}")

    print("Done! All 'N' images processed.")